##importing the data###
LungCapData<-read.csv('C:\\Users\\shira\\Documents\\R scripts.csv', header = TRUE)
View(LungCapData)

#we want to examine the assumptions for a model of the relationship between Age (x variable) and Lung Capacity
names(LungCapData)
Age<-LungCapData$Age
LungCap<-LungCapData$LungCap
Height<-LungCapData$Height
Smoke<-LungCapData$Smoke
Gender<-LungCapData$Gender
Caesarean<-LungCapData$Caesarean
plot(Age, LungCap)

#fitting linear regression
mod<-lm(LungCap~Age)
summary(mod)
abline(mod) #adding regression line to model

##Assumptions
# 1) the Y-Values (or errors, 'e') are independent.
#this is confirmed only by data context

# 2) the Y-values can be expressed as a linear function of the x variable
# 3) equal variances (homoscedasticity) 
# 4) normal distribution of errors

plot(mod) #hit return in the console
#the residual plot has a flat red line which shows linearity is met
#scattered points show constant variation
#the q-q plot shows the normal distribution of errors, it follows the line
par(mfrow=c(2,2)) #doing this and next shows all 4 plots on one screen
plot(mod)

###################Multiple Linear Regression#######

#our outcome variable is lungCap
#age and height are our explanatory variables
model1<-lm(LungCap~Age+Height)
summary(model1)
#r2 of 0.843, approx 84% of variation in LungCap can be explained by Age and Height
#y-intercept is mean LungCap for someone with age and height as 0
#Age estimate is .1264 meaning for every 1 year increase in age, LungCap increases by .1264 controlling for height

#calculating Pearson's Correlatoon for Age and Height
cor(Age, Height, method='pearson')
#.8357, the two are highly correlated, we need to deal with collinearity

#creating a confidence interval
confint(model1, conf.level=0.95)
#95% confident that true age effect is between (interval)

#fit a model using all of our variables
model2<-lm(LungCap~Age+Height+Smoke+Gender+Caesarean)
summary(model2)

#checking assumptions
plot(model2)
#residuals vs fitted looks good
#q-q plot looks good

############################attempting interaction#######################
#first step is plotting the data for non-smokers, in blue
plot(Age[Smoke=="no"], LungCap[Smoke=="no"], col="blue", ylim=c(0,15), xlim=c(0,20), xlab="Age",
     ylab="LungCap", main="LungCap vs Age, Smoke")

#adding in points for the smokers
points(Age[Smoke=="yes"], LungCap[Smoke=="yes"], col="red", pch=16)

#legend
legend(1,15, legend=c("nonsmoker", "smoker"), col=c("blue", "red"), pch=c(1,16), bty="n")

#the affect of Age is modified by Smoking

#fitting a regression model with Age, Smoke, and the interaction
model3<-lm(LungCap~Age*Smoke) #we can also do lm(LungCap~Age+Smoke+Age:Smoke)
coef(model3)
#we can now calculate the regression lines for smokers (1) and nonsmokers (0, this is binary variable)

#adding in the regression lines
abline(a=1.052, b=.558, col="blue", lwd=3) #a value got from nonsmokers regression line
abline(a=1.278, b=.490, col="red", lwd=3) 
#get values from regression lines by plugging in coefficients from coef(model3) into equation

#should we include this interaction? 
#does it make sense conceptually? Does it change with age? probably not
#is the interaction signficiant
summary(model3)
#p-value is high, NOT significant
#since both questions' answers are not yes, we dont include the interaction



